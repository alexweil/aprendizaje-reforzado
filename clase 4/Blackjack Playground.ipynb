{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "if \"../\" not in sys.path:\n",
    "  sys.path.append(\"../\") \n",
    "from lib.envs.blackjack import BlackjackEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = BlackjackEnv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_epsilon_greedy_policy(Q, epsilon, nA):\n",
    "    \"\"\"\n",
    "    Crea una política epsilon-greedy basado en una q-función (función de valor estado-acción) y un epsilon dados.\n",
    "    \n",
    "    Argumentos:\n",
    "        Q: un diccionario que mapea cada estado/observación s a un array de numpy Q[s] = array([v_0, v_1, ... , v_nA]) de longitud nA\n",
    "        que para un índice a del array contiene el valor v_a de tomar la acción a en el estado s. \n",
    "        (en nuestra notación de la clase q(s,a))\n",
    "         \n",
    "        epsilon: probabilidad de seleccionar una acción aleatoria (obliga a explorar), valor entre 0 y 1.\n",
    "        \n",
    "        nA: número de acciones en el entorno\n",
    "    \n",
    "    Retorna:\n",
    "        Una función que dada una observación como argumento, retorna una política (un array de numpy de longitud nA)\n",
    "        con probabilidades para cada acción. La política es tal que toma la mejor acción según Q con probabilidad (1-epsilon)\n",
    "        y toma una acción al azar con probabilidad epsilon\n",
    "        \n",
    "    \"\"\"\n",
    "    def policy_fn(observation):\n",
    "        policy = np.full(nA, epsilon / nA)\n",
    "        best_action = Q[observation].argmax()\n",
    "        policy[best_action] += 1 - epsilon\n",
    "        return policy\n",
    "        \n",
    "    return policy_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_control_epsilon_greedy(env, num_episodes, discount_factor=1.0, epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Control Monte Carlo utiliando políticas epsilon-greedy\n",
    "    Encuentra la política epsilon-greedy óptima.\n",
    "    \n",
    "    Argumentos:\n",
    "        env: ambiente de OpenAI gym.\n",
    "        num_episodes: número de episodios a samplear.\n",
    "        discount_factor: factor de descuento gama.\n",
    "        epsilon: probabilidad de samplear una acción aleatoria. Valor entre 0 y 1.\n",
    "    \n",
    "    Retorna:\n",
    "        Una tupla (Q, policy)\n",
    "        Q es un diccionario que mapea cada estado/observación s a un array de numpy Q[s] = array([v_0, v_1, ... , v_nA]) de longitud nA\n",
    "        que para un índice a del array contiene el valor v_a de tomar la acción a en el estado s. \n",
    "        (en nuestra notación de la clase q(s,a))\n",
    "        policy es una función que toma una observación/estado como argumento y retorna un array numpy \n",
    "        de longitud nA con las probabilidades de cada acción\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    returns_sum = defaultdict(float)\n",
    "    returns_count = defaultdict(float)\n",
    "    \n",
    "    Q = defaultdict(lambda: np.zeros(env.action_space.n))\n",
    "    \n",
    "    policy = make_epsilon_greedy_policy(Q, epsilon, env.action_space.n)\n",
    "        \n",
    "    for ep in range(num_episodes):\n",
    "        if ep % 1000 == 0:\n",
    "            print(ep)\n",
    "        \n",
    "        state = env.reset()        \n",
    "        steps = []\n",
    "        \n",
    "        for t in range(100):\n",
    "            prob_actions = policy(state)\n",
    "            action = np.random.choice(prob_actions.shape[0], p=prob_actions)\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            steps.append((state, action, reward))\n",
    "            state = next_state\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        for q in range(t, 0, -1):\n",
    "            state, action, reward = steps[q]\n",
    "            \n",
    "            G = 0\n",
    "            if (state, action, reward) not in steps[0:q]:\n",
    "                G = reward + discount_factor * G\n",
    "                \n",
    "                if (state, action) in returns_sum:\n",
    "                    returns_sum[(state, action)] += G\n",
    "                else:\n",
    "                    returns_sum[(state, action)] = G\n",
    "                    \n",
    "                if (state, action) in returns_count: \n",
    "                    returns_count[(state, action)] += 1\n",
    "                else:\n",
    "                    returns_count[(state, action)] = 1\n",
    "                    \n",
    "                Q[state][action] = returns_sum[(state, action)] / returns_count[(state, action)]\n",
    "    \n",
    "    return Q, policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n",
      "30000\n",
      "31000\n",
      "32000\n",
      "33000\n",
      "34000\n",
      "35000\n",
      "36000\n",
      "37000\n",
      "38000\n",
      "39000\n",
      "40000\n",
      "41000\n",
      "42000\n",
      "43000\n",
      "44000\n",
      "45000\n",
      "46000\n",
      "47000\n",
      "48000\n",
      "49000\n",
      "50000\n",
      "51000\n",
      "52000\n",
      "53000\n",
      "54000\n",
      "55000\n",
      "56000\n",
      "57000\n",
      "58000\n",
      "59000\n",
      "60000\n",
      "61000\n",
      "62000\n",
      "63000\n",
      "64000\n",
      "65000\n",
      "66000\n",
      "67000\n",
      "68000\n",
      "69000\n",
      "70000\n",
      "71000\n",
      "72000\n",
      "73000\n",
      "74000\n",
      "75000\n",
      "76000\n",
      "77000\n",
      "78000\n",
      "79000\n",
      "80000\n",
      "81000\n",
      "82000\n",
      "83000\n",
      "84000\n",
      "85000\n",
      "86000\n",
      "87000\n",
      "88000\n",
      "89000\n",
      "90000\n",
      "91000\n",
      "92000\n",
      "93000\n",
      "94000\n",
      "95000\n",
      "96000\n",
      "97000\n",
      "98000\n",
      "99000\n",
      "100000\n",
      "101000\n",
      "102000\n",
      "103000\n",
      "104000\n",
      "105000\n",
      "106000\n",
      "107000\n",
      "108000\n",
      "109000\n",
      "110000\n",
      "111000\n",
      "112000\n",
      "113000\n",
      "114000\n",
      "115000\n",
      "116000\n",
      "117000\n",
      "118000\n",
      "119000\n",
      "120000\n",
      "121000\n",
      "122000\n",
      "123000\n",
      "124000\n",
      "125000\n",
      "126000\n",
      "127000\n",
      "128000\n",
      "129000\n",
      "130000\n",
      "131000\n",
      "132000\n",
      "133000\n",
      "134000\n",
      "135000\n",
      "136000\n",
      "137000\n",
      "138000\n",
      "139000\n",
      "140000\n",
      "141000\n",
      "142000\n",
      "143000\n",
      "144000\n",
      "145000\n",
      "146000\n",
      "147000\n",
      "148000\n",
      "149000\n",
      "150000\n",
      "151000\n",
      "152000\n",
      "153000\n",
      "154000\n",
      "155000\n",
      "156000\n",
      "157000\n",
      "158000\n",
      "159000\n",
      "160000\n",
      "161000\n",
      "162000\n",
      "163000\n",
      "164000\n",
      "165000\n",
      "166000\n",
      "167000\n",
      "168000\n",
      "169000\n",
      "170000\n",
      "171000\n",
      "172000\n",
      "173000\n",
      "174000\n",
      "175000\n",
      "176000\n",
      "177000\n",
      "178000\n",
      "179000\n",
      "180000\n",
      "181000\n",
      "182000\n",
      "183000\n",
      "184000\n",
      "185000\n",
      "186000\n",
      "187000\n",
      "188000\n",
      "189000\n",
      "190000\n",
      "191000\n",
      "192000\n",
      "193000\n",
      "194000\n",
      "195000\n",
      "196000\n",
      "197000\n",
      "198000\n",
      "199000\n",
      "200000\n",
      "201000\n",
      "202000\n",
      "203000\n",
      "204000\n",
      "205000\n",
      "206000\n",
      "207000\n",
      "208000\n",
      "209000\n",
      "210000\n",
      "211000\n",
      "212000\n",
      "213000\n",
      "214000\n",
      "215000\n",
      "216000\n",
      "217000\n",
      "218000\n",
      "219000\n",
      "220000\n",
      "221000\n",
      "222000\n",
      "223000\n",
      "224000\n",
      "225000\n",
      "226000\n",
      "227000\n",
      "228000\n",
      "229000\n",
      "230000\n",
      "231000\n",
      "232000\n",
      "233000\n",
      "234000\n",
      "235000\n",
      "236000\n",
      "237000\n",
      "238000\n",
      "239000\n",
      "240000\n",
      "241000\n",
      "242000\n",
      "243000\n",
      "244000\n",
      "245000\n",
      "246000\n",
      "247000\n",
      "248000\n",
      "249000\n",
      "250000\n",
      "251000\n",
      "252000\n",
      "253000\n",
      "254000\n",
      "255000\n",
      "256000\n",
      "257000\n",
      "258000\n",
      "259000\n",
      "260000\n",
      "261000\n",
      "262000\n",
      "263000\n",
      "264000\n",
      "265000\n",
      "266000\n",
      "267000\n",
      "268000\n",
      "269000\n",
      "270000\n",
      "271000\n",
      "272000\n",
      "273000\n",
      "274000\n",
      "275000\n",
      "276000\n",
      "277000\n",
      "278000\n",
      "279000\n",
      "280000\n",
      "281000\n",
      "282000\n",
      "283000\n",
      "284000\n",
      "285000\n",
      "286000\n",
      "287000\n",
      "288000\n",
      "289000\n",
      "290000\n",
      "291000\n",
      "292000\n",
      "293000\n",
      "294000\n",
      "295000\n",
      "296000\n",
      "297000\n",
      "298000\n",
      "299000\n",
      "300000\n",
      "301000\n",
      "302000\n",
      "303000\n",
      "304000\n",
      "305000\n",
      "306000\n",
      "307000\n",
      "308000\n",
      "309000\n",
      "310000\n",
      "311000\n",
      "312000\n",
      "313000\n",
      "314000\n",
      "315000\n",
      "316000\n",
      "317000\n",
      "318000\n",
      "319000\n",
      "320000\n",
      "321000\n",
      "322000\n",
      "323000\n",
      "324000\n",
      "325000\n",
      "326000\n",
      "327000\n",
      "328000\n",
      "329000\n",
      "330000\n",
      "331000\n",
      "332000\n",
      "333000\n",
      "334000\n",
      "335000\n",
      "336000\n",
      "337000\n",
      "338000\n",
      "339000\n",
      "340000\n",
      "341000\n",
      "342000\n",
      "343000\n",
      "344000\n",
      "345000\n",
      "346000\n",
      "347000\n",
      "348000\n",
      "349000\n",
      "350000\n",
      "351000\n",
      "352000\n",
      "353000\n",
      "354000\n",
      "355000\n",
      "356000\n",
      "357000\n",
      "358000\n",
      "359000\n",
      "360000\n",
      "361000\n",
      "362000\n",
      "363000\n",
      "364000\n",
      "365000\n",
      "366000\n",
      "367000\n",
      "368000\n",
      "369000\n",
      "370000\n",
      "371000\n",
      "372000\n",
      "373000\n",
      "374000\n",
      "375000\n",
      "376000\n",
      "377000\n",
      "378000\n",
      "379000\n",
      "380000\n",
      "381000\n",
      "382000\n",
      "383000\n",
      "384000\n",
      "385000\n",
      "386000\n",
      "387000\n",
      "388000\n",
      "389000\n",
      "390000\n",
      "391000\n",
      "392000\n",
      "393000\n",
      "394000\n",
      "395000\n",
      "396000\n",
      "397000\n",
      "398000\n",
      "399000\n",
      "400000\n",
      "401000\n",
      "402000\n",
      "403000\n",
      "404000\n",
      "405000\n",
      "406000\n",
      "407000\n",
      "408000\n",
      "409000\n",
      "410000\n",
      "411000\n",
      "412000\n",
      "413000\n",
      "414000\n",
      "415000\n",
      "416000\n",
      "417000\n",
      "418000\n",
      "419000\n",
      "420000\n",
      "421000\n",
      "422000\n",
      "423000\n",
      "424000\n",
      "425000\n",
      "426000\n",
      "427000\n",
      "428000\n",
      "429000\n",
      "430000\n",
      "431000\n",
      "432000\n",
      "433000\n",
      "434000\n",
      "435000\n",
      "436000\n",
      "437000\n",
      "438000\n",
      "439000\n",
      "440000\n",
      "441000\n",
      "442000\n",
      "443000\n",
      "444000\n",
      "445000\n",
      "446000\n",
      "447000\n",
      "448000\n",
      "449000\n",
      "450000\n",
      "451000\n",
      "452000\n",
      "453000\n",
      "454000\n",
      "455000\n",
      "456000\n",
      "457000\n",
      "458000\n",
      "459000\n",
      "460000\n",
      "461000\n",
      "462000\n",
      "463000\n",
      "464000\n",
      "465000\n",
      "466000\n",
      "467000\n",
      "468000\n",
      "469000\n",
      "470000\n",
      "471000\n",
      "472000\n",
      "473000\n",
      "474000\n",
      "475000\n",
      "476000\n",
      "477000\n",
      "478000\n",
      "479000\n",
      "480000\n",
      "481000\n",
      "482000\n",
      "483000\n",
      "484000\n",
      "485000\n",
      "486000\n",
      "487000\n",
      "488000\n",
      "489000\n",
      "490000\n",
      "491000\n",
      "492000\n",
      "493000\n",
      "494000\n",
      "495000\n",
      "496000\n",
      "497000\n",
      "498000\n",
      "499000\n"
     ]
    }
   ],
   "source": [
    "Q, policy = mc_control_epsilon_greedy(env, num_episodes=500000, epsilon=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strategy(observation):\n",
    "    prob = policy(observation)\n",
    "    return np.random.choice([0, 1], p=prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_observation(observation):\n",
    "    score, dealer_score, usable_ace = observation\n",
    "    print(\"Player Score: {} (Usable Ace: {}), Dealer Score: {}\".format(\n",
    "          score, usable_ace, dealer_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player Score: 17 (Usable Ace: True), Dealer Score: 9\n",
      "Taking action: Hit\n",
      "Player Score: 20 (Usable Ace: True), Dealer Score: 9\n",
      "Taking action: Stick\n",
      "Player Score: 20 (Usable Ace: True), Dealer Score: 9\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 13 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Hit\n",
      "Player Score: 14 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Hit\n",
      "Player Score: 21 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 21 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 18 (Usable Ace: False), Dealer Score: 3\n",
      "Taking action: Stick\n",
      "Player Score: 18 (Usable Ace: False), Dealer Score: 3\n",
      "Game end. Reward: 0.0\n",
      "\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 3\n",
      "Taking action: Stick\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 3\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 21 (Usable Ace: True), Dealer Score: 8\n",
      "Taking action: Stick\n",
      "Player Score: 21 (Usable Ace: True), Dealer Score: 8\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 21 (Usable Ace: True), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 21 (Usable Ace: True), Dealer Score: 10\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 15 (Usable Ace: False), Dealer Score: 8\n",
      "Taking action: Hit\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 8\n",
      "Taking action: Hit\n",
      "Player Score: 20 (Usable Ace: False), Dealer Score: 8\n",
      "Taking action: Stick\n",
      "Player Score: 20 (Usable Ace: False), Dealer Score: 8\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 19 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 19 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 20 (Usable Ace: True), Dealer Score: 1\n",
      "Taking action: Hit\n",
      "Player Score: 20 (Usable Ace: False), Dealer Score: 1\n",
      "Taking action: Stick\n",
      "Player Score: 20 (Usable Ace: False), Dealer Score: 1\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 19 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 19 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 14 (Usable Ace: False), Dealer Score: 5\n",
      "Taking action: Stick\n",
      "Player Score: 14 (Usable Ace: False), Dealer Score: 5\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 18 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 18 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 12 (Usable Ace: False), Dealer Score: 9\n",
      "Taking action: Hit\n",
      "Player Score: 14 (Usable Ace: False), Dealer Score: 9\n",
      "Taking action: Hit\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 9\n",
      "Taking action: Stick\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 9\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 21 (Usable Ace: True), Dealer Score: 7\n",
      "Taking action: Stick\n",
      "Player Score: 21 (Usable Ace: True), Dealer Score: 7\n",
      "Game end. Reward: 1.0\n",
      "\n",
      "Player Score: 13 (Usable Ace: False), Dealer Score: 5\n",
      "Taking action: Stick\n",
      "Player Score: 13 (Usable Ace: False), Dealer Score: 5\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 20 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 20 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Hit\n",
      "Player Score: 26 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 18 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 18 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 16 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Hit\n",
      "Player Score: 24 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: -1.0\n",
      "\n",
      "Player Score: 17 (Usable Ace: False), Dealer Score: 10\n",
      "Taking action: Stick\n",
      "Player Score: 17 (Usable Ace: False), Dealer Score: 10\n",
      "Game end. Reward: -1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(100):\n",
    "        print_observation(observation)\n",
    "        action = strategy(observation)\n",
    "        print(\"Taking action: {}\".format( [\"Stick\", \"Hit\"][action]))\n",
    "        observation, reward, done, _ = env.step(action)\n",
    "        if done:\n",
    "            print_observation(observation)\n",
    "            print(\"Game end. Reward: {}\\n\".format(float(reward)))\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
